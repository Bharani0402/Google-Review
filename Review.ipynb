{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "978f138d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 8 reviews...\n",
      "Fetched 18 reviews...\n",
      "Fetched 28 reviews...\n",
      "Fetched 38 reviews...\n",
      "Fetched 48 reviews...\n",
      "Fetched 58 reviews...\n",
      "Fetched 68 reviews...\n",
      "Fetched 78 reviews...\n",
      "Fetched 88 reviews...\n",
      "Fetched 98 reviews...\n",
      "Fetched 108 reviews...\n",
      "Fetched 118 reviews...\n",
      "Fetched 128 reviews...\n",
      "Fetched 138 reviews...\n",
      "Fetched 148 reviews...\n",
      "Fetched 158 reviews...\n",
      "Fetched 168 reviews...\n",
      "Fetched 178 reviews...\n",
      "Fetched 188 reviews...\n",
      "Fetched 198 reviews...\n",
      "Fetched 208 reviews...\n",
      "\n",
      "Total reviews collected: 200\n"
     ]
    }
   ],
   "source": [
    "#1d16ff4e05892ef89e252027fe4770959c28aff707f48ce2b46fbf75fc37c6f4\n",
    "\n",
    "\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "API_KEY = \"1d16ff4e05892ef89e252027fe4770959c28aff707f48ce2b46fbf75fc37c6f4\"\n",
    "PLACE_ID = \"ChIJLU7jZClu5kcR4PcOOO6p3I0\"\n",
    "\n",
    "all_reviews = []\n",
    "next_page_token = None\n",
    "MAX_REVIEWS = 200   # change to 50 / 100 / 200\n",
    "\n",
    "while len(all_reviews) < MAX_REVIEWS:\n",
    "    params = {\n",
    "        \"engine\": \"google_maps_reviews\",\n",
    "        \"place_id\": PLACE_ID,\n",
    "        \"hl\": \"en\",\n",
    "        \"api_key\": API_KEY\n",
    "    }\n",
    "\n",
    "    if next_page_token:\n",
    "        params[\"next_page_token\"] = next_page_token\n",
    "\n",
    "    response = requests.get(\"https://serpapi.com/search.json\", params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    reviews = data.get(\"reviews\", [])\n",
    "    all_reviews.extend(reviews)\n",
    "\n",
    "    print(f\"Fetched {len(all_reviews)} reviews...\")\n",
    "\n",
    "    # Get next page token\n",
    "    pagination = data.get(\"serpapi_pagination\", {})\n",
    "    next_page_token = pagination.get(\"next_page_token\")\n",
    "\n",
    "    if not next_page_token:\n",
    "        break\n",
    "\n",
    "    time.sleep(2)  # IMPORTANT: avoid rate limit\n",
    "\n",
    "# Trim to exact count\n",
    "all_reviews = all_reviews[:MAX_REVIEWS]\n",
    "\n",
    "print(f\"\\nTotal reviews collected: {len(all_reviews)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd4fcd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved reviews to CSV and JSON\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "structured_reviews = []\n",
    "\n",
    "for r in all_reviews:\n",
    "    structured_reviews.append({\n",
    "        \"User\": r.get(\"user\", {}).get(\"name\"),\n",
    "        \"Rating\": r.get(\"rating\"),\n",
    "        \"Date\": r.get(\"date\"),\n",
    "        \"Review Text\": r.get(\"snippet\")\n",
    "    })\n",
    "\n",
    "# Save as JSON\n",
    "with open(\"google_maps_reviews.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(structured_reviews, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Save as CSV\n",
    "df = pd.DataFrame(structured_reviews)\n",
    "df.to_csv(\"google_maps_reviews.csv\", index=False)\n",
    "\n",
    "print(\"Saved reviews to CSV and JSON\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56c63931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: click in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\eshwar\\appdata\\roaming\\python\\python313\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9e9afa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Eshwar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ec07440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned reviews saved successfully\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df = pd.DataFrame(structured_reviews)\n",
    "\n",
    "# Apply preprocessing\n",
    "df[\"clean_text\"] = df[\"Review Text\"].apply(clean_text)\n",
    "df[\"review_length\"] = df[\"clean_text\"].apply(len)\n",
    "df[\"word_count\"] = df[\"clean_text\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Save cleaned data\n",
    "\n",
    "\n",
    "print(\"Cleaned reviews saved successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4012a220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp313-cp313-win_amd64.whl.metadata (30 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.20.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\eshwar\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Collecting setuptools (from torch)\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\eshwar\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (2025.8.3)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 3.1/12.0 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.2/12.0 MB 10.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.2/12.0 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.8/12.0 MB 7.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.3/12.0 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.8/12.0 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.6/12.0 MB 5.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.1/12.0 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.7/12.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.2/12.0 MB 4.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.0/12.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.0/12.0 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 4.3 MB/s  0:00:02\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 566.1/566.1 kB 4.2 MB/s  0:00:00\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   --------------------------- ------------ 1.8/2.7 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.7 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 5.9 MB/s  0:00:00\n",
      "Downloading torch-2.9.1-cp313-cp313-win_amd64.whl (110.9 MB)\n",
      "   ---------------------------------------- 0.0/110.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/110.9 MB 4.3 MB/s eta 0:00:26\n",
      "    --------------------------------------- 2.1/110.9 MB 5.3 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 3.1/110.9 MB 5.4 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 3.9/110.9 MB 4.8 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 4.7/110.9 MB 4.7 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 6.0/110.9 MB 4.8 MB/s eta 0:00:22\n",
      "   -- ------------------------------------- 7.3/110.9 MB 4.9 MB/s eta 0:00:21\n",
      "   --- ------------------------------------ 8.7/110.9 MB 5.1 MB/s eta 0:00:21\n",
      "   --- ------------------------------------ 8.9/110.9 MB 4.7 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 9.2/110.9 MB 4.4 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 9.4/110.9 MB 4.1 MB/s eta 0:00:25\n",
      "   --- ------------------------------------ 10.0/110.9 MB 3.9 MB/s eta 0:00:26\n",
      "   --- ------------------------------------ 10.7/110.9 MB 3.9 MB/s eta 0:00:26\n",
      "   ---- ----------------------------------- 11.8/110.9 MB 4.0 MB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 13.6/110.9 MB 4.3 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 14.4/110.9 MB 4.3 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 15.2/110.9 MB 4.2 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 16.5/110.9 MB 4.3 MB/s eta 0:00:22\n",
      "   ------ --------------------------------- 17.8/110.9 MB 4.4 MB/s eta 0:00:22\n",
      "   ------ --------------------------------- 18.9/110.9 MB 4.5 MB/s eta 0:00:21\n",
      "   ------- -------------------------------- 19.9/110.9 MB 4.5 MB/s eta 0:00:21\n",
      "   ------- -------------------------------- 20.7/110.9 MB 4.5 MB/s eta 0:00:21\n",
      "   ------- -------------------------------- 21.5/110.9 MB 4.4 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 22.8/110.9 MB 4.5 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 23.9/110.9 MB 4.5 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 24.6/110.9 MB 4.5 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 25.7/110.9 MB 4.5 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 26.5/110.9 MB 4.5 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 26.7/110.9 MB 4.4 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 27.5/110.9 MB 4.4 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 28.3/110.9 MB 4.4 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 28.6/110.9 MB 4.3 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 29.1/110.9 MB 4.2 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 29.4/110.9 MB 4.1 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 30.4/110.9 MB 4.1 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 31.5/110.9 MB 4.2 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 33.0/110.9 MB 4.2 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 33.6/110.9 MB 4.2 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 34.3/110.9 MB 4.2 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 34.9/110.9 MB 4.2 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 35.9/110.9 MB 4.2 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 37.0/110.9 MB 4.2 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 38.3/110.9 MB 4.2 MB/s eta 0:00:18\n",
      "   -------------- ------------------------- 39.3/110.9 MB 4.2 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 40.6/110.9 MB 4.3 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 41.2/110.9 MB 4.3 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 41.7/110.9 MB 4.2 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 42.7/110.9 MB 4.2 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 44.0/110.9 MB 4.3 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 45.1/110.9 MB 4.3 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 45.6/110.9 MB 4.3 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 46.1/110.9 MB 4.2 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 46.7/110.9 MB 4.2 MB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 47.4/110.9 MB 4.2 MB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 49.0/110.9 MB 4.2 MB/s eta 0:00:15\n",
      "   ------------------ --------------------- 50.6/110.9 MB 4.3 MB/s eta 0:00:15\n",
      "   ------------------ --------------------- 51.9/110.9 MB 4.3 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 52.7/110.9 MB 4.3 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 53.5/110.9 MB 4.3 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 54.5/110.9 MB 4.3 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 55.8/110.9 MB 4.3 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 57.1/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 58.2/110.9 MB 4.4 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 59.0/110.9 MB 4.4 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 59.5/110.9 MB 4.4 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 60.6/110.9 MB 4.3 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 61.9/110.9 MB 4.4 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 63.2/110.9 MB 4.4 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 64.0/110.9 MB 4.4 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 64.5/110.9 MB 4.4 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 65.0/110.9 MB 4.4 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 66.1/110.9 MB 4.4 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 67.4/110.9 MB 4.4 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 68.9/110.9 MB 4.4 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 70.3/110.9 MB 4.4 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 70.8/110.9 MB 4.4 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 71.0/110.9 MB 4.4 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 71.3/110.9 MB 4.4 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 71.6/110.9 MB 4.3 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 71.6/110.9 MB 4.3 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 71.8/110.9 MB 4.2 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 72.1/110.9 MB 4.2 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 72.1/110.9 MB 4.2 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 72.4/110.9 MB 4.1 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 72.6/110.9 MB 4.1 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 73.9/110.9 MB 4.1 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 75.2/110.9 MB 4.1 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 76.3/110.9 MB 4.1 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 77.1/110.9 MB 4.1 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 78.1/110.9 MB 4.1 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 79.2/110.9 MB 4.1 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 79.7/110.9 MB 4.1 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 79.7/110.9 MB 4.1 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 80.0/110.9 MB 4.1 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 80.0/110.9 MB 4.1 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 80.5/110.9 MB 4.0 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 80.7/110.9 MB 3.9 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 82.1/110.9 MB 3.9 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 83.4/110.9 MB 4.0 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 84.7/110.9 MB 4.0 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 85.7/110.9 MB 4.0 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 86.5/110.9 MB 4.0 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 87.3/110.9 MB 4.0 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 88.1/110.9 MB 4.0 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 89.1/110.9 MB 4.0 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 90.4/110.9 MB 4.0 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 91.2/110.9 MB 4.0 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 92.3/110.9 MB 4.0 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 93.6/110.9 MB 4.0 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 94.4/110.9 MB 4.0 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 94.9/110.9 MB 4.0 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 95.4/110.9 MB 4.0 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 96.2/110.9 MB 4.0 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 97.0/110.9 MB 4.0 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 98.3/110.9 MB 4.0 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 99.4/110.9 MB 4.0 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 100.4/110.9 MB 4.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 101.2/110.9 MB 4.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 102.2/110.9 MB 4.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 103.3/110.9 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 104.3/110.9 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 105.4/110.9 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 106.4/110.9 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 107.2/110.9 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 108.0/110.9 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  108.8/110.9 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  109.3/110.9 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  110.1/110.9 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  110.9/110.9 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  110.9/110.9 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  110.9/110.9 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 110.9/110.9 MB 4.0 MB/s  0:00:27\n",
      "Downloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
      "Downloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.3/2.1 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 6.0 MB/s  0:00:00\n",
      "Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.6/6.3 MB 8.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 3.4/6.3 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.5/6.3 MB 7.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.0/6.3 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.8/6.3 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 5.1 MB/s  0:00:01\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 3.5 MB/s  0:00:00\n",
      "Downloading filelock-3.20.1-py3-none-any.whl (16 kB)\n",
      "Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------- ----- 1.0/1.2 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 5.1 MB/s  0:00:00\n",
      "Installing collected packages: mpmath, sympy, setuptools, safetensors, networkx, fsspec, filelock, torch, huggingface-hub, tokenizers, transformers\n",
      "\n",
      "   ----------------------------------------  0/11 [mpmath]\n",
      "   ----------------------------------------  0/11 [mpmath]\n",
      "   ----------------------------------------  0/11 [mpmath]\n",
      "   ----------------------------------------  0/11 [mpmath]\n",
      "   ----------------------------------------  0/11 [mpmath]\n",
      "   ----------------------------------------  0/11 [mpmath]\n",
      "   ----------------------------------------  0/11 [mpmath]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   ------- --------------------------------  2/11 [setuptools]\n",
      "   ------- --------------------------------  2/11 [setuptools]\n",
      "   ------- --------------------------------  2/11 [setuptools]\n",
      "   ------- --------------------------------  2/11 [setuptools]\n",
      "   ------- --------------------------------  2/11 [setuptools]\n",
      "   ------- --------------------------------  2/11 [setuptools]\n",
      "   ------- --------------------------------  2/11 [setuptools]\n",
      "   ------- --------------------------------  2/11 [setuptools]\n",
      "   ------- --------------------------------  2/11 [setuptools]\n",
      "   ------- --------------------------------  2/11 [setuptools]\n",
      "   ------- --------------------------------  2/11 [setuptools]\n",
      "   ------- --------------------------------  2/11 [setuptools]\n",
      "   ------- --------------------------------  2/11 [setuptools]\n",
      "   ------- --------------------------------  2/11 [setuptools]\n",
      "   ------- --------------------------------  2/11 [setuptools]\n",
      "   ------- --------------------------------  2/11 [setuptools]\n",
      "   ---------- -----------------------------  3/11 [safetensors]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [networkx]\n",
      "   ------------------ ---------------------  5/11 [fsspec]\n",
      "   ------------------ ---------------------  5/11 [fsspec]\n",
      "   --------------------- ------------------  6/11 [filelock]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ------------------------- --------------  7/11 [torch]\n",
      "   ----------------------------- ----------  8/11 [huggingface-hub]\n",
      "   ----------------------------- ----------  8/11 [huggingface-hub]\n",
      "   ----------------------------- ----------  8/11 [huggingface-hub]\n",
      "   ----------------------------- ----------  8/11 [huggingface-hub]\n",
      "   ----------------------------- ----------  8/11 [huggingface-hub]\n",
      "   ----------------------------- ----------  8/11 [huggingface-hub]\n",
      "   ----------------------------- ----------  8/11 [huggingface-hub]\n",
      "   -------------------------------- -------  9/11 [tokenizers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [transformers]\n",
      "   ---------------------------------------- 11/11 [transformers]\n",
      "\n",
      "Successfully installed filelock-3.20.1 fsspec-2025.12.0 huggingface-hub-0.36.0 mpmath-1.3.0 networkx-3.6.1 safetensors-0.7.0 setuptools-80.9.0 sympy-1.14.0 tokenizers-0.22.1 torch-2.9.1 transformers-4.57.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff3b193e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sentiment & Topic extraction completed\n",
      "              User  Rating          Date  \\\n",
      "0  Charlie Jameson     5.0   a month ago   \n",
      "1             4.0    a week ago   \n",
      "2            L A K     5.0   3 weeks ago   \n",
      "3        Amrit Das     5.0  2 months ago   \n",
      "4      Husam Qissi     5.0   2 weeks ago   \n",
      "\n",
      "                                         Review Text  \\\n",
      "0  One of the most iconic experiences you can hav...   \n",
      "1  The Eiffel Tower is one of the most iconic mon...   \n",
      "2  The Eiffel Tower is honestly better in real li...   \n",
      "3  \\tNo ticket needed: You dont have to buy a t...   \n",
      "4  No matter how familiar you think you are with ...   \n",
      "\n",
      "                                          clean_text  review_length  \\\n",
      "0  one iconic experiences paris visited november ...            792   \n",
      "1  eiffel tower one iconic monuments world visiti...            759   \n",
      "2  eiffel tower honestly better real life photos ...            594   \n",
      "3  ticket needed dont buy ticket enter tower queu...           1338   \n",
      "4  matter familiar think photos since childhood o...            207   \n",
      "\n",
      "   word_count Sentiment       Topics  \n",
      "0         106  positive     ambience  \n",
      "1         100  positive  cleanliness  \n",
      "2          89  positive     ambience  \n",
      "3         187  positive      pricing  \n",
      "4          29  positive     ambience  \n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# IMPORTS\n",
    "# ================================\n",
    "import re\n",
    "import json\n",
    "import nltk\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    pipeline\n",
    ")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# ================================\n",
    "# NLTK SETUP\n",
    "# ================================\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# ================================\n",
    "# LOAD REVIEWS (FROM SERPAPI STEP)\n",
    "# ================================\n",
    "df = pd.read_csv(\"google_maps_reviews.csv\")\n",
    "\n",
    "# ================================\n",
    "# TEXT PREPROCESSING (ALREADY DONE  SAFE)\n",
    "# ================================\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"clean_text\"] = df[\"Review Text\"].apply(clean_text)\n",
    "df[\"review_length\"] = df[\"clean_text\"].apply(len)\n",
    "df[\"word_count\"] = df[\"clean_text\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "# ================================\n",
    "# SENTIMENT ANALYSIS (RoBERTa)\n",
    "# ================================\n",
    "SENTIMENT_MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "sentiment_tokenizer = AutoTokenizer.from_pretrained(SENTIMENT_MODEL)\n",
    "sentiment_config = AutoConfig.from_pretrained(SENTIMENT_MODEL)\n",
    "sentiment_model = AutoModelForSequenceClassification.from_pretrained(SENTIMENT_MODEL)\n",
    "sentiment_model.eval()\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    if not text:\n",
    "        return \"Neutral\"\n",
    "\n",
    "    encoded = sentiment_tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = sentiment_model(**encoded)\n",
    "\n",
    "    scores = softmax(output.logits[0].detach().numpy())\n",
    "    label_id = np.argmax(scores)\n",
    "\n",
    "    return sentiment_config.id2label[label_id]\n",
    "\n",
    "df[\"Sentiment\"] = df[\"clean_text\"].apply(predict_sentiment)\n",
    "\n",
    "# ================================\n",
    "# TOPIC EXTRACTION (Zero-Shot)\n",
    "# ================================\n",
    "topic_classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"facebook/bart-large-mnli\"\n",
    ")\n",
    "\n",
    "TOPICS = [\n",
    "    \"service\",\n",
    "    \"pricing\",\n",
    "    \"ambience\",\n",
    "    \"staff\",\n",
    "    \"food quality\",\n",
    "    \"cleanliness\",\n",
    "    \"delivery\"\n",
    "]\n",
    "\n",
    "def extract_topics(text, threshold=0.3):\n",
    "    if not text:\n",
    "        return []\n",
    "\n",
    "    result = topic_classifier(text, TOPICS)\n",
    "    return [\n",
    "        label for label, score in zip(result[\"labels\"], result[\"scores\"])\n",
    "        if score >= threshold\n",
    "    ]\n",
    "\n",
    "df[\"Topics\"] = df[\"clean_text\"].apply(lambda x: \", \".join(extract_topics(x)))\n",
    "\n",
    "# ================================\n",
    "# SAVE FINAL OUTPUT\n",
    "# ================================\n",
    "df.to_csv(\"google_maps_reviews_final.csv\", index=False)\n",
    "\n",
    "print(\" Sentiment & Topic extraction completed\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a0d5f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved updated file: google_maps_reviews_with_dates.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# -------------------------------\n",
    "# Relative date parser\n",
    "# -------------------------------\n",
    "def parse_relative_date(text):\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "\n",
    "    text = text.lower().strip()\n",
    "    today = datetime.today()\n",
    "\n",
    "    if text == \"today\":\n",
    "        return today\n",
    "    if text == \"yesterday\":\n",
    "        return today - timedelta(days=1)\n",
    "\n",
    "    match = re.search(r\"(\\d+)\\s+(day|week|month|year)s?\\s+ago\", text)\n",
    "\n",
    "    if match:\n",
    "        value = int(match.group(1))\n",
    "        unit = match.group(2)\n",
    "\n",
    "        if unit == \"day\":\n",
    "            return today - timedelta(days=value)\n",
    "        if unit == \"week\":\n",
    "            return today - timedelta(weeks=value)\n",
    "        if unit == \"month\":\n",
    "            return today - timedelta(days=value * 30)\n",
    "        if unit == \"year\":\n",
    "            return today - timedelta(days=value * 365)\n",
    "\n",
    "    return None\n",
    "\n",
    "# -------------------------------\n",
    "# Load CSV\n",
    "# -------------------------------\n",
    "df = pd.read_csv(\"google_maps_reviews_final.csv\")\n",
    "\n",
    "# -------------------------------\n",
    "# Apply date parsing\n",
    "# -------------------------------\n",
    "df[\"Parsed_Date\"] = df[\"Date\"].apply(parse_relative_date)\n",
    "\n",
    "# Remove rows where date could not be parsed\n",
    "df = df.dropna(subset=[\"Parsed_Date\"])\n",
    "\n",
    "# Create week & month columns\n",
    "df[\"Week\"] = df[\"Parsed_Date\"].dt.to_period(\"W\").astype(str)\n",
    "df[\"Month\"] = df[\"Parsed_Date\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "# -------------------------------\n",
    "# SAVE UPDATED CSV\n",
    "# -------------------------------\n",
    "df.to_csv(\"google_maps_reviews_with_dates.csv\", index=False)\n",
    "\n",
    "print(\" Saved updated file: google_maps_reviews_with_dates.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1610ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " WEEKLY INSIGHTS\n",
      "                    Week  Total Reviews  Average Rating Top Sentiment  \\\n",
      "0  2025-08-11/2025-08-17              5            4.60      positive   \n",
      "1  2025-09-08/2025-09-14             19            4.89      positive   \n",
      "2  2025-10-13/2025-10-19             26            4.96      positive   \n",
      "3  2025-11-10/2025-11-16             45            4.91      positive   \n",
      "4  2025-12-15/2025-12-21              6            4.83      positive   \n",
      "5  2025-12-22/2025-12-28             20            4.75      positive   \n",
      "6  2025-12-29/2026-01-04             19            4.89      positive   \n",
      "\n",
      "                             Top Topics  \n",
      "0            service, pricing, ambience  \n",
      "1  ambience, service, ambience, service  \n",
      "2  ambience, ambience, service, service  \n",
      "3            ambience, service, pricing  \n",
      "4       ambience, pricing, food quality  \n",
      "5  ambience, service, service, ambience  \n",
      "6            ambience, service, pricing  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"google_maps_reviews_with_dates.csv\")\n",
    "\n",
    "weekly_insights = []\n",
    "\n",
    "for week, group in df.groupby(\"Week\"):\n",
    "    insight = {\n",
    "        \"Week\": week,\n",
    "        \"Total Reviews\": len(group),\n",
    "        \"Average Rating\": round(group[\"Rating\"].mean(), 2),\n",
    "        \"Top Sentiment\": group[\"Sentiment\"].value_counts().idxmax(),\n",
    "        \"Top Topics\": \", \".join(group[\"Topics\"].value_counts().head(3).index.tolist())\n",
    "    }\n",
    "    weekly_insights.append(insight)\n",
    "\n",
    "weekly_df = pd.DataFrame(weekly_insights)\n",
    "weekly_df.to_csv(\"weekly_insights.csv\", index=False)\n",
    "\n",
    "print(\"\\n WEEKLY INSIGHTS\")\n",
    "print(weekly_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51e793f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MONTHLY INSIGHTS\n",
      "     Month  Total Reviews  Average Rating Top Sentiment  \\\n",
      "0  2025-08              5            4.60      positive   \n",
      "1  2025-09             19            4.89      positive   \n",
      "2  2025-10             26            4.96      positive   \n",
      "3  2025-11             45            4.91      positive   \n",
      "4  2025-12             45            4.82      positive   \n",
      "\n",
      "                             Top Topics  \n",
      "0            service, pricing, ambience  \n",
      "1  ambience, service, ambience, service  \n",
      "2  ambience, ambience, service, service  \n",
      "3            ambience, service, pricing  \n",
      "4            ambience, service, pricing  \n"
     ]
    }
   ],
   "source": [
    "monthly_insights = []\n",
    "\n",
    "for month, group in df.groupby(\"Month\"):\n",
    "    insight = {\n",
    "        \"Month\": month,\n",
    "        \"Total Reviews\": len(group),\n",
    "        \"Average Rating\": round(group[\"Rating\"].mean(), 2),\n",
    "        \"Top Sentiment\": group[\"Sentiment\"].value_counts().idxmax(),\n",
    "        \"Top Topics\": \", \".join(group[\"Topics\"].value_counts().head(3).index.tolist())\n",
    "    }\n",
    "    monthly_insights.append(insight)\n",
    "\n",
    "monthly_df = pd.DataFrame(monthly_insights)\n",
    "monthly_df.to_csv(\"monthly_insights.csv\", index=False)\n",
    "\n",
    "print(\"\\n MONTHLY INSIGHTS\")\n",
    "print(monthly_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e598135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.2.3)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-1.1.7-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: openai in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (1.2.7)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (1.0.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (2.12.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.6.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\eshwar\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (4.14.1)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.2)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai)\n",
      "  Downloading tiktoken-0.12.0-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\eshwar\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\eshwar\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\eshwar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\eshwar\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading langchain_openai-1.1.7-py3-none-any.whl (84 kB)\n",
      "Downloading tiktoken-0.12.0-cp313-cp313-win_amd64.whl (879 kB)\n",
      "   ---------------------------------------- 0.0/879.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 879.1/879.1 kB 8.4 MB/s  0:00:00\n",
      "Installing collected packages: tiktoken, langchain-openai\n",
      "\n",
      "   -------------------- ------------------- 1/2 [langchain-openai]\n",
      "   ---------------------------------------- 2/2 [langchain-openai]\n",
      "\n",
      "Successfully installed langchain-openai-1.1.7 tiktoken-0.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-openai openai pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b55e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c97c431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d1c8c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def call_llm(prompt, max_tokens=300):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a business analyst.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0331cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Month: 2025-08\n",
      "Average Rating: 4.6\n",
      "Sentiment Distribution: {'positive': 5}\n",
      "Top Topics: {'service': 3, 'pricing': 1, 'ambience': 1}\n",
      "\n",
      "\n",
      "Month: 2025-09\n",
      "Average Rating: 4.89\n",
      "Sentiment Distribution: {'positive': 18, 'neutral': 1}\n",
      "Top Topics: {'ambience': 12, 'service': 4, ' service': 1, 'cleanliness': 1, ' ambience': 1}\n",
      "\n",
      "\n",
      "Month: 2025-10\n",
      "Average Rating: 4.96\n",
      "Sentiment Distribution: {'positive': 25, 'negative': 1}\n",
      "Top Topics: {'ambience': 18, 'service': 5, ' service': 3, ' staff': 1, 'cleanliness': 1}\n",
      "\n",
      "\n",
      "Month: 2025-11\n",
      "Average Rating: 4.91\n",
      "Sentiment Distribution: {'positive': 43, 'neutral': 1, 'negative': 1}\n",
      "Top Topics: {'ambience': 22, 'service': 11, ' ambience': 4, 'pricing': 3, 'food quality': 3}\n",
      "\n",
      "\n",
      "Month: 2025-12\n",
      "Average Rating: 4.82\n",
      "Sentiment Distribution: {'positive': 41, 'neutral': 3, 'negative': 1}\n",
      "Top Topics: {'ambience': 27, 'service': 7, 'pricing': 5, ' ambience': 2, ' service': 2}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalize column names\n",
    "df.columns = (\n",
    "    df.columns\n",
    "      .str.strip()\n",
    "      .str.lower()\n",
    "      .str.replace(\" \", \"_\")\n",
    ")\n",
    "\n",
    "# Convert parsed_date\n",
    "df[\"parsed_date\"] = pd.to_datetime(df[\"parsed_date\"], errors=\"coerce\")\n",
    "\n",
    "# Drop invalid dates\n",
    "df = df.dropna(subset=[\"parsed_date\"])\n",
    "\n",
    "# Create month column\n",
    "df[\"month\"] = df[\"parsed_date\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "analysis_blocks = []\n",
    "\n",
    "for month, group in df.groupby(\"month\"):\n",
    "    sentiment = group[\"sentiment\"].value_counts().to_dict()\n",
    "    topics = (\n",
    "        group[\"topics\"]\n",
    "        .dropna()\n",
    "        .str.split(\",\")\n",
    "        .explode()\n",
    "        .value_counts()\n",
    "        .head(5)\n",
    "        .to_dict()\n",
    "    )\n",
    "    avg_rating = round(group[\"rating\"].mean(), 2)\n",
    "\n",
    "    block = f\"\"\"\n",
    "Month: {month}\n",
    "Average Rating: {avg_rating}\n",
    "Sentiment Distribution: {sentiment}\n",
    "Top Topics: {topics}\n",
    "\"\"\"\n",
    "    analysis_blocks.append(block)\n",
    "\n",
    "analysis_text = \"\\n\".join(analysis_blocks)\n",
    "\n",
    "print(analysis_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92b726d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "operational_prompt = f\"\"\"\n",
    "Based on the customer review insights below, suggest OPERATIONAL IMPROVEMENTS.\n",
    "\n",
    "Guidelines:\n",
    "- Focus on service, staffing, pricing, cleanliness, ambience\n",
    "- Provide actionable steps\n",
    "- Prioritize negative or neutral sentiment\n",
    "- Give 23 bullet points per issue\n",
    "\n",
    "Customer Review Insights:\n",
    "{analysis_text}\n",
    "\"\"\"\n",
    "\n",
    "operational_suggestions = call_llm(operational_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "538f3ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_prompt = f\"\"\"\n",
    "Analyze trends in customer sentiment, ratings, and topics over time.\n",
    "\n",
    "Tasks:\n",
    "- Identify improving trends\n",
    "- Identify declining trends\n",
    "- Suggest strategic actions\n",
    "- Highlight risks and opportunities\n",
    "\n",
    "Customer Review Trends:\n",
    "{analysis_text}\n",
    "\"\"\"\n",
    "\n",
    "trend_recommendations = call_llm(trend_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56d2abcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "competitor_prompt = f\"\"\"\n",
    "Using the customer review data below, generate competitor comparison insights.\n",
    "\n",
    "Assume competitors are similar businesses in the same category.\n",
    "\n",
    "Highlight:\n",
    "- Competitive strengths\n",
    "- Weaknesses\n",
    "- Customer expectations\n",
    "- Strategic positioning\n",
    "\n",
    "Customer Review Analysis:\n",
    "{analysis_text}\n",
    "\"\"\"\n",
    "\n",
    "competitor_highlights = call_llm(competitor_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "569cd7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " OPERATIONAL IMPROVEMENT SUGGESTIONS\n",
      "\n",
      "Based on the customer review insights, here are actionable operational improvements focused on service, staffing, pricing, cleanliness, and ambience. The suggestions prioritize addressing negative or neutral sentiments.\n",
      "\n",
      "### 1. **Service Improvement**\n",
      "- **Staff Training**: Implement regular training sessions for staff on customer service best practices, focusing on communication skills and responsiveness to enhance the overall customer experience.\n",
      "- **Feedback Mechanism**: Establish a real-time feedback system where customers can rate their service experience immediately after their visit. Use this data to identify areas for improvement and recognize high-performing staff.\n",
      "- **Staffing Levels**: Assess peak hours and adjust staffing levels accordingly to ensure that customers receive timely service, reducing wait times and improving satisfaction.\n",
      "\n",
      "### 2. **Staffing Enhancement**\n",
      "- **Hiring Strategy**: Review and enhance the hiring process to attract candidates with strong customer service backgrounds. Consider implementing a trial period where new hires are evaluated based on customer interactions.\n",
      "- **Employee Engagement**: Foster a positive work environment by regularly engaging with staff through surveys or meetings to understand their challenges and gather suggestions for improvement.\n",
      "- **Incentive Programs**: Introduce incentive programs for staff based on customer feedback and service quality, motivating them to provide exceptional service.\n",
      "\n",
      "### 3. **Pricing Strategy**\n",
      "- **Competitive Analysis**: Conduct a thorough analysis of competitors pricing and offerings to ensure that your pricing is competitive while still reflecting the quality of service and experience provided.\n",
      "- **Transparent Pricing**: Clearly communicate pricing structures to customers\n",
      "\n",
      " TREND-BASED BUSINESS RECOMMENDATIONS\n",
      "\n",
      "### Analysis of Customer Review Trends\n",
      "\n",
      "#### Improving Trends\n",
      "1. **Average Rating**: The average rating has shown a consistent upward trend from 4.6 in August to a peak of 4.96 in October, with only a slight decline to 4.82 in December. This indicates a strong overall customer satisfaction trajectory.\n",
      "  \n",
      "2. **Positive Sentiment**: The number of positive sentiments has increased significantly, from 5 in August to 43 in November. This suggests that more customers are having positive experiences.\n",
      "\n",
      "3. **Top Topics**: The topics of \"ambience\" and \"service\" have consistently appeared in the top topics, indicating that these areas are being positively received by customers. The increase in mentions of \"food quality\" in November also suggests an improvement in this area.\n",
      "\n",
      "#### Declining Trends\n",
      "1. **Average Rating Decline**: Although the average rating peaked in October, it slightly declined in November and December. This could indicate a potential plateau or slight dissatisfaction that needs to be addressed.\n",
      "\n",
      "2. **Negative Sentiment**: The presence of negative sentiments, although low, has remained steady at 1 in November and December. This indicates that there are still some customers who are not fully satisfied.\n",
      "\n",
      "3. **Neutral Sentiment**: The number of neutral sentiments increased in December, which may suggest that while many customers are satisfied, some are indifferent or have mixed feelings about their experiences.\n",
      "\n",
      "#### Strategic Actions\n",
      "1. **Focus on Ambience and Service\n",
      "\n",
      " COMPETITOR COMPARISON HIGHLIGHTS\n",
      "\n",
      "Based on the customer review data provided for the months of August to December 2025, we can derive several insights regarding competitive strengths, weaknesses, customer expectations, and strategic positioning in the market.\n",
      "\n",
      "### Competitive Strengths:\n",
      "1. **High Average Ratings**: The business consistently maintains high average ratings (ranging from 4.6 to 4.96), indicating strong customer satisfaction and loyalty.\n",
      "2. **Positive Sentiment**: The sentiment distribution shows a predominance of positive reviews, especially in the months of September to December, where the number of positive reviews significantly outweighs neutral and negative ones.\n",
      "3. **Ambience as a Key Strength**: The topic of 'ambience' is frequently mentioned across all months, suggesting that the business excels in creating a pleasant environment that resonates well with customers.\n",
      "4. **Service Quality**: The service received positive mentions consistently, indicating that customer service is a strong point, with numerous reviews highlighting attentive and friendly staff.\n",
      "\n",
      "### Weaknesses:\n",
      "1. **Pricing Concerns**: Pricing is mentioned as a topic in several months, particularly in November and December. While the average rating remains high, the presence of pricing discussions suggests that some customers may perceive the offerings as expensive or not providing sufficient value.\n",
      "2. **Negative Feedback**: There are instances of negative reviews, although they are minimal compared to positive ones. Addressing the concerns raised in these reviews could further enhance customer satisfaction.\n",
      "\n",
      "### Customer Expectations:\n",
      "1. **Quality of Ambience\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n OPERATIONAL IMPROVEMENT SUGGESTIONS\\n\")\n",
    "print(operational_suggestions)\n",
    "\n",
    "print(\"\\n TREND-BASED BUSINESS RECOMMENDATIONS\\n\")\n",
    "print(trend_recommendations)\n",
    "\n",
    "print(\"\\n COMPETITOR COMPARISON HIGHLIGHTS\\n\")\n",
    "print(competitor_highlights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d4dca95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Final CSV created successfully!\n",
      " Columns: ['date', 'review_text', 'rating', 'sentiment', 'topics', 'user']\n",
      " Total rows: 140\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>topics</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-12-22 12:37:44.562957</td>\n",
       "      <td>The Eiffel Tower is honestly better in real li...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>ambience</td>\n",
       "      <td>L A K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-13 12:37:44.563408</td>\n",
       "      <td>\\tNo ticket needed: You dont have to buy a t...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>pricing</td>\n",
       "      <td>Amrit Das</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-12-29 12:37:44.563444</td>\n",
       "      <td>No matter how familiar you think you are with ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>ambience</td>\n",
       "      <td>Husam Qissi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-12-29 12:37:44.563454</td>\n",
       "      <td>First time ever to see this iconic French Beau...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>ambience</td>\n",
       "      <td>NIKKI D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-12-29 12:37:44.563463</td>\n",
       "      <td>The Eiffel Tower is an absolute icon and a mus...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>ambience</td>\n",
       "      <td>Arunas Jag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2025-11-13 12:37:44.565081</td>\n",
       "      <td>Such a wonderful experience, we walked all the...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>service</td>\n",
       "      <td>Abby Latham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2025-09-14 12:37:44.565086</td>\n",
       "      <td>Great experience. Ordered tickets in advance f...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>service</td>\n",
       "      <td>Anna Kuksenko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2025-09-14 12:37:44.565092</td>\n",
       "      <td>5/5   Eiffel Tower\\nAn absolute must-see in ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>cleanliness, ambience</td>\n",
       "      <td>Kareem A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2025-11-13 12:37:44.565104</td>\n",
       "      <td>The Eiffel Tower is as beautiful as always! Th...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>ambience</td>\n",
       "      <td>Margarita Shevchuk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2025-10-14 12:37:44.565109</td>\n",
       "      <td>Absolutely fantastic experience visiting this ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>ambience</td>\n",
       "      <td>J Youde</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date  \\\n",
       "0   2025-12-22 12:37:44.562957   \n",
       "1   2025-11-13 12:37:44.563408   \n",
       "2   2025-12-29 12:37:44.563444   \n",
       "3   2025-12-29 12:37:44.563454   \n",
       "4   2025-12-29 12:37:44.563463   \n",
       "..                         ...   \n",
       "135 2025-11-13 12:37:44.565081   \n",
       "136 2025-09-14 12:37:44.565086   \n",
       "137 2025-09-14 12:37:44.565092   \n",
       "138 2025-11-13 12:37:44.565104   \n",
       "139 2025-10-14 12:37:44.565109   \n",
       "\n",
       "                                           review_text  rating sentiment  \\\n",
       "0    The Eiffel Tower is honestly better in real li...     5.0  positive   \n",
       "1    \\tNo ticket needed: You dont have to buy a t...     5.0  positive   \n",
       "2    No matter how familiar you think you are with ...     5.0  positive   \n",
       "3    First time ever to see this iconic French Beau...     5.0  positive   \n",
       "4    The Eiffel Tower is an absolute icon and a mus...     5.0  positive   \n",
       "..                                                 ...     ...       ...   \n",
       "135  Such a wonderful experience, we walked all the...     5.0  positive   \n",
       "136  Great experience. Ordered tickets in advance f...     5.0  positive   \n",
       "137  5/5   Eiffel Tower\\nAn absolute must-see in ...     5.0  positive   \n",
       "138  The Eiffel Tower is as beautiful as always! Th...     4.0  positive   \n",
       "139  Absolutely fantastic experience visiting this ...     5.0  positive   \n",
       "\n",
       "                    topics                user  \n",
       "0                 ambience               L A K  \n",
       "1                  pricing           Amrit Das  \n",
       "2                 ambience         Husam Qissi  \n",
       "3                 ambience             NIKKI D  \n",
       "4                 ambience          Arunas Jag  \n",
       "..                     ...                 ...  \n",
       "135                service         Abby Latham  \n",
       "136                service       Anna Kuksenko  \n",
       "137  cleanliness, ambience            Kareem A  \n",
       "138               ambience  Margarita Shevchuk  \n",
       "139               ambience             J Youde  \n",
       "\n",
       "[140 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ================================\n",
    "# LOAD SOURCE FILE\n",
    "# ================================\n",
    "input_file = \"google_maps_reviews_with_dates.csv\"\n",
    "output_file = \"google_maps_reviews_final.csv\"\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# ================================\n",
    "# CLEAN COLUMN NAMES\n",
    "# ================================\n",
    "df.columns = (\n",
    "    df.columns\n",
    "      .str.strip()\n",
    "      .str.lower()\n",
    "      .str.replace(\" \", \"_\")\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# CREATE FINAL STRUCTURE\n",
    "# ================================\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "final_df[\"date\"] = pd.to_datetime(df[\"parsed_date\"], errors=\"coerce\")\n",
    "final_df[\"review_text\"] = df[\"review_text\"]\n",
    "final_df[\"rating\"] = df[\"rating\"]\n",
    "final_df[\"sentiment\"] = df[\"sentiment\"]\n",
    "final_df[\"topics\"] = df[\"topics\"]\n",
    "final_df[\"user\"] = df[\"user\"]\n",
    "\n",
    "# ================================\n",
    "# DROP INVALID ROWS\n",
    "# ================================\n",
    "final_df = final_df.dropna(subset=[\"date\", \"review_text\"])\n",
    "\n",
    "# ================================\n",
    "# SAVE FINAL CSV\n",
    "# ================================\n",
    "final_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(\" Final CSV created successfully!\")\n",
    "print(\" Columns:\", final_df.columns.tolist())\n",
    "print(\" Total rows:\", len(final_df))\n",
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
